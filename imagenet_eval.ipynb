{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from regnet import RegNet, MODELS\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all available model names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(MODELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, device, criterion=None):\n",
    "    loss_value = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            if out.size(1) == 1:\n",
    "                # regression\n",
    "                out = torch.squeeze(out, 1)\n",
    "\n",
    "            if criterion is not None:\n",
    "                loss = criterion(out, yb)\n",
    "                loss_value.append(loss.item())\n",
    "\n",
    "            y_pred.append(out.detach().cpu())\n",
    "            y_true.append(yb.detach().cpu())\n",
    "\n",
    "    if criterion is not None:\n",
    "        loss_value = sum(loss_value) / len(loss_value)\n",
    "        return torch.cat(y_pred), torch.cat(y_true), loss_value\n",
    "    else:\n",
    "        return torch.cat(y_pred), torch.cat(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device', device)\n",
    "\n",
    "val_trainsforms = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=Image.BICUBIC),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# set 'root' to path that contains following validation subset files for imagenet dataset:\n",
    "# ILSVRC2012_devkit_t12.tar.gz\n",
    "# ILSVRC2012_img_val.tar\n",
    "# meta.bin\n",
    "# To download ImageNet dataset: http://image-net.org/download\n",
    "val_dataset = datasets.ImageNet(root=\"/path/to/imagenet/dataset/\", split=\"val\",\n",
    "                                transform=val_trainsforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myregnet_scores = {}\n",
    "for key in MODELS.keys():\n",
    "    model = RegNet(key, pretrained=True)\n",
    "    model.to(device)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32, shuffle=False,\n",
    "        num_workers=2, pin_memory=True)\n",
    "    \n",
    "    y_pred, y_true = eval_model(model, val_loader, device)\n",
    "    _, y_pred = torch.max(y_pred, 1)\n",
    "\n",
    "    score = accuracy_score(y_pred, y_true)\n",
    "    error = 1 - score\n",
    "    print(f\"{key}: Accuracy: {score:.4%}, Error: {error:.4%}\")\n",
    "    myregnet_scores[key] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected evaluation accuracy values on ImageNet validation set \n",
    "\n",
    "RegNetX-200MF: Accuracy: 69.7180%, Error: 30.2820%  \n",
    "RegNetX-400MF: Accuracy: 73.4700%, Error: 26.5300%  \n",
    "RegNetX-600MF: Accuracy: 74.7540%, Error: 25.2460%  \n",
    "RegNetX-800MF: Accuracy: 75.6620%, Error: 24.3380%  \n",
    "RegNetX-1.6GF: Accuracy: 77.6320%, Error: 22.3680%  \n",
    "RegNetX-3.2GF: Accuracy: 78.8500%, Error: 21.1500%  \n",
    "RegNetX-4.0GF: Accuracy: 79.0600%, Error: 20.9400%  \n",
    "RegNetX-6.4GF: Accuracy: 79.5560%, Error: 20.4440%  \n",
    "RegNetX-8.0GF: Accuracy: 79.7840%, Error: 20.2160%  \n",
    "RegNetX-12GF: Accuracy: 80.1380%, Error: 19.8620%  \n",
    "RegNetX-16GF: Accuracy: 80.5600%, Error: 19.4400%  \n",
    "RegNetX-32GF: Accuracy: 80.7760%, Error: 19.2240%  \n",
    "RegNetY-200MF: Accuracy: 71.3560%, Error: 28.6440%  \n",
    "RegNetY-400MF: Accuracy: 74.9200%, Error: 25.0800%  \n",
    "RegNetY-600MF: Accuracy: 76.1820%, Error: 23.8180%  \n",
    "RegNetY-800MF: Accuracy: 77.1060%, Error: 22.8940%  \n",
    "RegNetY-1.6GF: Accuracy: 78.6800%, Error: 21.3200%  \n",
    "RegNetY-3.2GF: Accuracy: 79.5800%, Error: 20.4200%  \n",
    "RegNetY-4.0GF: Accuracy: 80.1120%, Error: 19.8880%  \n",
    "RegNetY-6.4GF: Accuracy: 80.5120%, Error: 19.4880%  \n",
    "RegNetY-8.0GF: Accuracy: 80.6140%, Error: 19.3860%  \n",
    "RegNetY-12GF: Accuracy: 81.0520%, Error: 18.9480%  \n",
    "RegNetY-16GF: Accuracy: 81.1040%, Error: 18.8960%  \n",
    "RegNetY-32GF: Accuracy: 81.4640%, Error: 18.5360%  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
